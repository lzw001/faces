{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faces_cnn_lenet.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "AuzP0X019K5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "2d87594d-581c-4fc6-e31e-a2876f9342ae"
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/stasulam/faces.git@cnn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/stasulam/faces.git@cnn\n",
            "  Cloning https://github.com/stasulam/faces.git (to revision cnn) to /tmp/pip-req-build-pzoupk0f\n",
            "Branch 'cnn' set up to track remote branch 'cnn' from 'origin'.\n",
            "Switched to a new branch 'cnn'\n",
            "Requirement already satisfied (use --upgrade to upgrade): faces==0.1 from git+https://github.com/stasulam/faces.git@cnn in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: beautifulsoup4==4.6.1 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (4.6.1)\n",
            "Requirement already satisfied: certifi==2018.11.29 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (2018.11.29)\n",
            "Requirement already satisfied: dlib==19.16.0 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (19.16.0)\n",
            "Requirement already satisfied: imutils==0.5.2 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (0.5.2)\n",
            "Requirement already satisfied: joblib==0.13.1 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (0.13.1)\n",
            "Requirement already satisfied: lxml==4.2.5 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (4.2.5)\n",
            "Requirement already satisfied: numpy==1.16.0 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (1.16.0)\n",
            "Requirement already satisfied: opencv-python==4.0.0.21 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (4.0.0.21)\n",
            "Requirement already satisfied: powerline-status==2.7 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (2.7)\n",
            "Requirement already satisfied: scikit-learn==0.20.1 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (0.20.1)\n",
            "Requirement already satisfied: scipy==1.2.0 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (1.2.0)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (0.9.0)\n",
            "Requirement already satisfied: tqdm==4.29.1 in /usr/local/lib/python3.6/dist-packages (from faces==0.1) (4.29.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0->faces==0.1) (3.0.2)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0->faces==0.1) (0.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->faces==0.1) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->faces==0.1) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->faces==0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->faces==0.1) (2.3.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn==0.9.0->faces==0.1) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn==0.9.0->faces==0.1) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn==0.9.0->faces==0.1) (40.6.3)\n",
            "Building wheels for collected packages: faces\n",
            "  Running setup.py bdist_wheel for faces ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-5nudledx/wheels/c8/e3/b9/764bc63312620f531fea42459fa5d49d05ea226a097959ae37\n",
            "Successfully built faces\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "grvfGzbi_QXI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mount `Drive`. Images are stored in `Colab Notebooks` directory. We will use **global** variable, ie. `DIR` to manage access for `Dataset` class."
      ]
    },
    {
      "metadata": {
        "id": "YiEy6OCM9q29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64d09e3b-d9f2-43d8-bfe1-cbae23db784d"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pOpA2iFg_wpy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define `torch.transformers` which will be used in image preprocessing."
      ]
    },
    {
      "metadata": {
        "id": "owvfAMI9-b0-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oG91s6G5ARCD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`FacesDataset` inherit methods from pytorch's `Dataset` in order to provide object, which will be used by `torch.utils.data.DataLoader`."
      ]
    },
    {
      "metadata": {
        "id": "IWODhO7C_0Nj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from faces.preprocessing import FacesDataset\n",
        "\n",
        "DIR = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "\n",
        "# train set\n",
        "trainset = FacesDataset(\n",
        "    path_to_images=os.path.join(DIR, 'data/train/*/*.jpg'),\n",
        "    transform=transform\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=4,\n",
        "    shuffle=4,\n",
        "    num_workers=2\n",
        ")\n",
        "# test set\n",
        "testset = FacesDataset(\n",
        "    path_to_images=os.path.join(DIR, 'data/test/*/*.jpg'),\n",
        "    transform=transform\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C3JELeSWBbyG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define `LeNet` architecture suited for images of size `600x600`."
      ]
    },
    {
      "metadata": {
        "id": "7wCaBBENBtSc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 147 * 147, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 147 * 147)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "net = LeNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_4_i_ob1CgLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c3e8a9b3-1046-431e-b4e6-bbfe9c16d939"
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "classes = {\n",
        "    'anna': torch.LongTensor([0]),\n",
        "    'lukasz': torch.LongTensor([1])\n",
        "}\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(1):\n",
        "    running_loss = 0.0\n",
        "    for step, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        labels = torch.cat([classes[label] for label in labels], 0)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if step % 50 == 49:\n",
        "            print('[%d, %4d] loss: %.9f' %\n",
        "                 (epoch + 1, step + 1, running_loss / 50))\n",
        "            running_loss = 0.0\n",
        "print('End!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   50] loss: 0.679658799\n",
            "[1,  100] loss: 0.000026855\n",
            "[1,  150] loss: 0.000008516\n",
            "[1,  200] loss: 0.000018330\n",
            "[1,  250] loss: 0.000008831\n",
            "[1,  300] loss: 0.000003414\n",
            "[1,  350] loss: 0.000013504\n",
            "End!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m9ufOEUrHmd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30951cc3-83de-4d31-d1e0-73d459d702ef"
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        labels = torch.cat([classes[label] for label in labels], 0)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network: 100 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}